{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "import os\n",
    "\n",
    "from imutils.video import FileVideoStream\n",
    "\n",
    "# Importing the libraries\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import YOLOModelDetector as md\n",
    "from PIL import Image, ImageDraw\n",
    "import copy\n",
    "\n",
    "from threading import Thread, Lock\n",
    "from queue import Queue\n",
    "import multiprocessing\n",
    "\n",
    "pos_face = Lock()\n",
    "pos_feature = Lock()\n",
    "rect_lock = Lock()\n",
    "face_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vid_path = 'overdose.mp4'\n",
    "result_path = 'over_e.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'wider.h5'\n"
     ]
    }
   ],
   "source": [
    "v = FileVideoStream(vid_path)\n",
    "vs = v.start()\n",
    "\n",
    "detector = md.ModelDetector()\n",
    "detector.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"shape_predictor_68_face_landmarks_GTX.dat\"\n",
    "predictor_of_landmark = dlib.shape_predictor(path)\n",
    "\n",
    "default_size = (int(v.stream.get(3)), int(v.stream.get(4)))\n",
    "#\n",
    "size = (560, 560)\n",
    "#\n",
    "result = cv2.VideoWriter(os.path.splitext(result_path)[0] + '.avi',\n",
    "                         cv2.VideoWriter_fourcc(*'MPEG'),\n",
    "                         60, size)\n",
    "#\n",
    "time.sleep(2.0)\n",
    "#\n",
    "frame_rate = 20\n",
    "prev = time.time()\n",
    "\n",
    "i = 0\n",
    "min_i = 10\n",
    "\n",
    "faceRects = []\n",
    "rect_raw = []\n",
    "\n",
    "face_in = Queue()\n",
    "face_out = Queue()\n",
    "feature_out = Queue()\n",
    "\n",
    "\n",
    "def predict_face(q, q_out_face, q_out_feature):\n",
    "    while True:\n",
    "        face = None\n",
    "        if q.empty() is False:\n",
    "            pos_face.acquire()\n",
    "            try:\n",
    "                face = q.get()\n",
    "                while q.empty() is False:\n",
    "                    q.get()\n",
    "            finally:\n",
    "                pos_face.release()\n",
    "\n",
    "        if face is not None:\n",
    "            print('p')\n",
    "            x = detector.detect(Image.fromarray(face))\n",
    "            pos_feature.acquire()\n",
    "            try:\n",
    "                while q_out_face.empty() is False:\n",
    "                    q_out_face.get()\n",
    "                q_out_face.put(x)\n",
    "            finally:\n",
    "                pos_feature.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "threads = [\n",
    "    Thread(target=predict_face,\n",
    "           args=(face_in, face_out, feature_out),\n",
    "           name='face_detect_thread' + str(i),\n",
    "           daemon=True)\n",
    "    for i in range(multiprocessing.cpu_count())\n",
    "]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "while vs.more():\n",
    "    # grab the frame from the video stream, resize it, and convert it\n",
    "    # to grayscale\n",
    "    i += 1\n",
    "    time_elapsed = time.time() - prev\n",
    "    if time_elapsed < 1. / frame_rate:\n",
    "\n",
    "        continue\n",
    "    else:\n",
    "        prev = time.time()\n",
    "\n",
    "    frame = vs.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    if i < min_i:\n",
    "        pass\n",
    "    else:\n",
    "        pos_face.acquire()\n",
    "        try:\n",
    "            face_in.put(copy.deepcopy(frame))\n",
    "        finally:\n",
    "            pos_face.release()\n",
    "        # predict_face(face_in, face_out, feature_out)\n",
    "        # predict_face()\n",
    "    # faceRects = detector.detect(Image.fromarray(frame))\n",
    "\n",
    "    # Replace this with your detect\n",
    "\n",
    "    # print('k')\n",
    "    # # print(len(face_out))\n",
    "    # print('k1')\n",
    "\n",
    "    pos_feature.acquire()\n",
    "    try:\n",
    "        while face_out.empty() is False:\n",
    "            faceRects = face_out.get()\n",
    "    finally:\n",
    "        pos_feature.release()\n",
    "\n",
    "    for (_, fX, fY, fW, fH) in faceRects:\n",
    "        # extract the face ROI\n",
    "        cv2.rectangle(frame, (fX.astype(int), fY.astype(int)), ((fX + fW).astype(int), (fY + fH).astype(int)),\n",
    "                      (0, 255, 0), 1)\n",
    "        rect = dlib.rectangle(fX.astype(int), fY.astype(int), (fX + fW).astype(int), (fY + fH).astype(int))\n",
    "        #\n",
    "        if i < min_i:\n",
    "            pass\n",
    "        else:\n",
    "            print('in here')\n",
    "            rect_raw = numpy.matrix([[p.x, p.y] for p in predictor_of_landmark(frame, rect).parts()])\n",
    "\n",
    "        for idx, point in enumerate(rect_raw):\n",
    "            cv2.circle(frame, (point[0, 0], point[0, 1]), 0, (255, 0, 0), -1)\n",
    "\n",
    "    if i < min_i:\n",
    "        pass\n",
    "    else:\n",
    "        i = 0\n",
    "\n",
    "    frame = cv2.resize(frame, size)\n",
    "\n",
    "    result.write(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "result.release()\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}